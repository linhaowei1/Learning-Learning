{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 调用必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. define hyperparameters\n",
    "BATCH_SIZE = 512 # 每批处理的数据\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu') # cpu训练，可选GPU \n",
    "EPOCHS = 10 # 训练10轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. transform\n",
    "TRANSFORM = transforms.Compose([\n",
    "    transforms.ToTensor(), #将图片转换为tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) #正则化，降低复杂度，更好generalization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. downloads datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 下载数据集\n",
    "train_set = datasets.MNIST(\"data\", train=True, download=True, transform=TRANSFORM) # 运用pytorch内置MNIST数据集\n",
    "\n",
    "test_set = datasets.MNIST(\"data\", train=False, download=True, transform=TRANSFORM)\n",
    "\n",
    "# 加载数据\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 构建网络模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5) # 1: 灰度图片的通道， 10：输出通道， 5：kernel\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3) # 10：输入通道 20：输出通道， 3：kernel大小\n",
    "        self.fc1 = nn.Linear(20*10*10, 500) # 20*10*10：输入通道，500：输出通道\n",
    "        self.fc2 = nn.Linear(500, 10) # 500：输入通道，10：输出通道\n",
    "    \n",
    "    def forward(self, x):\n",
    "        input_size = x.size(0) # batch_size * 1 * 28 * 28\n",
    "        x = self.conv1(x) # 输入：batch_size * 1 * 28 * 28, 输入：batch_size * 10* 24 * 24\n",
    "        x = F.relu(x) # 激活函数RELU，shape不变\n",
    "        x = F.max_pool2d(x, 2, 2) # 最大池化层，输入：batch_size*10*24*24，输出：batch*10*12*12\n",
    "        \n",
    "        x = self.conv2(x) # 输入：batch_size*10*12*12 输出：batch_size*20*10*10\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.view(input_size, -1) # 拉平，-1：自动计算维度，20*10*10 =2000\n",
    "        \n",
    "        x = self.fc1(x) # 输入：batch_size*2000 输出：batch_size*500\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x) # 输入：batch_size*500 输出：batch_size*10\n",
    "        \n",
    "        output = F.log_softmax(x, dim=1) # 计算分类后每个数据的概率值\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 定义优化器\n",
    "model = Net().to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters()) # 使用Adam优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 定义训练方法\n",
    "def train_model(model, device, train_loader, optimizer, epoch):\n",
    "    # 开始训练\n",
    "    model.train()\n",
    "    for batch_index, (data, target) in enumerate(train_loader):\n",
    "        # 数据部署到DEVICE上去\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # 梯度初始化为0\n",
    "        optimizer.zero_grad()\n",
    "        # 预测\n",
    "        output = model(data)\n",
    "        # 计算损失\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        # 找到概率值最大的下标\n",
    "        pred = output.argmax(dim=1) \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 参数优化\n",
    "        optimizer.step()\n",
    "        if batch_index % 10 == 0:\n",
    "            print(\"Train Epoch : {}, index : {} \\t Loss : {:.6f}\".format(epoch, batch_index, loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 定义测试方法\n",
    "def test_model(model, device, test_loader):\n",
    "    # 模型验证\n",
    "    model.eval()\n",
    "    # 正确率\n",
    "    correct = 0.0\n",
    "    # 测试损失\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad(): # 不计算梯度和反向传播\n",
    "        for data, target in test_loader:\n",
    "            # 部署到device上\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # 测试数据\n",
    "            output = model(data)\n",
    "            # 计算测试损失\n",
    "            test_loss += F.cross_entropy(output, target).item()\n",
    "            # 找到概率值最大的下标\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            # 累积正确率\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print(\"Test Average loss : {:.4f}, Accuracy : {:.3f}\\n\".format(\n",
    "              test_loss, 100.0 * correct / len(test_loader.dataset)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch : 1, index : 0 \t Loss : 2.307470\n",
      "Train Epoch : 1, index : 10 \t Loss : 0.564772\n",
      "Train Epoch : 1, index : 20 \t Loss : 0.466786\n",
      "Train Epoch : 1, index : 30 \t Loss : 0.291659\n",
      "Train Epoch : 1, index : 40 \t Loss : 0.308937\n",
      "Train Epoch : 1, index : 50 \t Loss : 0.223918\n",
      "Train Epoch : 1, index : 60 \t Loss : 0.206420\n",
      "Train Epoch : 1, index : 70 \t Loss : 0.174509\n",
      "Train Epoch : 1, index : 80 \t Loss : 0.151677\n",
      "Train Epoch : 1, index : 90 \t Loss : 0.137973\n",
      "Train Epoch : 1, index : 100 \t Loss : 0.129320\n",
      "Train Epoch : 1, index : 110 \t Loss : 0.119090\n",
      "Test Average loss : 0.0002, Accuracy : 97.090\n",
      "\n",
      "Train Epoch : 2, index : 0 \t Loss : 0.074841\n",
      "Train Epoch : 2, index : 10 \t Loss : 0.076890\n",
      "Train Epoch : 2, index : 20 \t Loss : 0.100701\n",
      "Train Epoch : 2, index : 30 \t Loss : 0.071623\n",
      "Train Epoch : 2, index : 40 \t Loss : 0.053419\n",
      "Train Epoch : 2, index : 50 \t Loss : 0.064680\n",
      "Train Epoch : 2, index : 60 \t Loss : 0.065044\n",
      "Train Epoch : 2, index : 70 \t Loss : 0.070620\n",
      "Train Epoch : 2, index : 80 \t Loss : 0.077371\n",
      "Train Epoch : 2, index : 90 \t Loss : 0.072954\n",
      "Train Epoch : 2, index : 100 \t Loss : 0.056638\n",
      "Train Epoch : 2, index : 110 \t Loss : 0.075925\n",
      "Test Average loss : 0.0001, Accuracy : 98.210\n",
      "\n",
      "Train Epoch : 3, index : 0 \t Loss : 0.071996\n",
      "Train Epoch : 3, index : 10 \t Loss : 0.043826\n",
      "Train Epoch : 3, index : 20 \t Loss : 0.063723\n",
      "Train Epoch : 3, index : 30 \t Loss : 0.075803\n",
      "Train Epoch : 3, index : 40 \t Loss : 0.042079\n",
      "Train Epoch : 3, index : 50 \t Loss : 0.048902\n",
      "Train Epoch : 3, index : 60 \t Loss : 0.070730\n",
      "Train Epoch : 3, index : 70 \t Loss : 0.072369\n",
      "Train Epoch : 3, index : 80 \t Loss : 0.059515\n",
      "Train Epoch : 3, index : 90 \t Loss : 0.038557\n",
      "Train Epoch : 3, index : 100 \t Loss : 0.057727\n",
      "Train Epoch : 3, index : 110 \t Loss : 0.041312\n",
      "Test Average loss : 0.0001, Accuracy : 98.630\n",
      "\n",
      "Train Epoch : 4, index : 0 \t Loss : 0.048553\n",
      "Train Epoch : 4, index : 10 \t Loss : 0.023423\n",
      "Train Epoch : 4, index : 20 \t Loss : 0.037733\n",
      "Train Epoch : 4, index : 30 \t Loss : 0.027165\n",
      "Train Epoch : 4, index : 40 \t Loss : 0.069291\n",
      "Train Epoch : 4, index : 50 \t Loss : 0.060656\n",
      "Train Epoch : 4, index : 60 \t Loss : 0.028145\n",
      "Train Epoch : 4, index : 70 \t Loss : 0.024525\n",
      "Train Epoch : 4, index : 80 \t Loss : 0.030507\n",
      "Train Epoch : 4, index : 90 \t Loss : 0.067933\n",
      "Train Epoch : 4, index : 100 \t Loss : 0.044001\n",
      "Train Epoch : 4, index : 110 \t Loss : 0.035676\n",
      "Test Average loss : 0.0001, Accuracy : 98.900\n",
      "\n",
      "Train Epoch : 5, index : 0 \t Loss : 0.033325\n",
      "Train Epoch : 5, index : 10 \t Loss : 0.015000\n",
      "Train Epoch : 5, index : 20 \t Loss : 0.017495\n",
      "Train Epoch : 5, index : 30 \t Loss : 0.021200\n",
      "Train Epoch : 5, index : 40 \t Loss : 0.016310\n",
      "Train Epoch : 5, index : 50 \t Loss : 0.046508\n",
      "Train Epoch : 5, index : 60 \t Loss : 0.033935\n",
      "Train Epoch : 5, index : 70 \t Loss : 0.054494\n",
      "Train Epoch : 5, index : 80 \t Loss : 0.045503\n",
      "Train Epoch : 5, index : 90 \t Loss : 0.031678\n",
      "Train Epoch : 5, index : 100 \t Loss : 0.031269\n",
      "Train Epoch : 5, index : 110 \t Loss : 0.014175\n",
      "Test Average loss : 0.0001, Accuracy : 98.860\n",
      "\n",
      "Train Epoch : 6, index : 0 \t Loss : 0.035958\n",
      "Train Epoch : 6, index : 10 \t Loss : 0.014618\n",
      "Train Epoch : 6, index : 20 \t Loss : 0.010639\n",
      "Train Epoch : 6, index : 30 \t Loss : 0.018345\n",
      "Train Epoch : 6, index : 40 \t Loss : 0.027659\n",
      "Train Epoch : 6, index : 50 \t Loss : 0.021537\n",
      "Train Epoch : 6, index : 60 \t Loss : 0.032613\n",
      "Train Epoch : 6, index : 70 \t Loss : 0.017358\n",
      "Train Epoch : 6, index : 80 \t Loss : 0.015094\n",
      "Train Epoch : 6, index : 90 \t Loss : 0.013446\n",
      "Train Epoch : 6, index : 100 \t Loss : 0.028066\n",
      "Train Epoch : 6, index : 110 \t Loss : 0.015840\n",
      "Test Average loss : 0.0001, Accuracy : 98.840\n",
      "\n",
      "Train Epoch : 7, index : 0 \t Loss : 0.023994\n",
      "Train Epoch : 7, index : 10 \t Loss : 0.013592\n",
      "Train Epoch : 7, index : 20 \t Loss : 0.050664\n",
      "Train Epoch : 7, index : 30 \t Loss : 0.013639\n",
      "Train Epoch : 7, index : 40 \t Loss : 0.018736\n",
      "Train Epoch : 7, index : 50 \t Loss : 0.014377\n",
      "Train Epoch : 7, index : 60 \t Loss : 0.027173\n",
      "Train Epoch : 7, index : 70 \t Loss : 0.020420\n",
      "Train Epoch : 7, index : 80 \t Loss : 0.019856\n",
      "Train Epoch : 7, index : 90 \t Loss : 0.031595\n",
      "Train Epoch : 7, index : 100 \t Loss : 0.026008\n",
      "Train Epoch : 7, index : 110 \t Loss : 0.022302\n",
      "Test Average loss : 0.0001, Accuracy : 99.040\n",
      "\n",
      "Train Epoch : 8, index : 0 \t Loss : 0.012545\n",
      "Train Epoch : 8, index : 10 \t Loss : 0.015059\n",
      "Train Epoch : 8, index : 20 \t Loss : 0.045726\n",
      "Train Epoch : 8, index : 30 \t Loss : 0.015202\n",
      "Train Epoch : 8, index : 40 \t Loss : 0.008521\n",
      "Train Epoch : 8, index : 50 \t Loss : 0.019921\n",
      "Train Epoch : 8, index : 60 \t Loss : 0.010844\n",
      "Train Epoch : 8, index : 70 \t Loss : 0.013287\n",
      "Train Epoch : 8, index : 80 \t Loss : 0.026250\n",
      "Train Epoch : 8, index : 90 \t Loss : 0.016602\n",
      "Train Epoch : 8, index : 100 \t Loss : 0.019020\n",
      "Train Epoch : 8, index : 110 \t Loss : 0.016739\n",
      "Test Average loss : 0.0001, Accuracy : 99.080\n",
      "\n",
      "Train Epoch : 9, index : 0 \t Loss : 0.005610\n",
      "Train Epoch : 9, index : 10 \t Loss : 0.012407\n",
      "Train Epoch : 9, index : 20 \t Loss : 0.009086\n",
      "Train Epoch : 9, index : 30 \t Loss : 0.013163\n",
      "Train Epoch : 9, index : 40 \t Loss : 0.008071\n",
      "Train Epoch : 9, index : 50 \t Loss : 0.004248\n",
      "Train Epoch : 9, index : 60 \t Loss : 0.014988\n",
      "Train Epoch : 9, index : 70 \t Loss : 0.010449\n",
      "Train Epoch : 9, index : 80 \t Loss : 0.009553\n",
      "Train Epoch : 9, index : 90 \t Loss : 0.006725\n",
      "Train Epoch : 9, index : 100 \t Loss : 0.011085\n",
      "Train Epoch : 9, index : 110 \t Loss : 0.010557\n",
      "Test Average loss : 0.0001, Accuracy : 99.060\n",
      "\n",
      "Train Epoch : 10, index : 0 \t Loss : 0.011795\n",
      "Train Epoch : 10, index : 10 \t Loss : 0.012910\n",
      "Train Epoch : 10, index : 20 \t Loss : 0.003764\n",
      "Train Epoch : 10, index : 30 \t Loss : 0.012796\n",
      "Train Epoch : 10, index : 40 \t Loss : 0.015214\n",
      "Train Epoch : 10, index : 50 \t Loss : 0.002113\n",
      "Train Epoch : 10, index : 60 \t Loss : 0.005354\n",
      "Train Epoch : 10, index : 70 \t Loss : 0.003564\n",
      "Train Epoch : 10, index : 80 \t Loss : 0.008579\n",
      "Train Epoch : 10, index : 90 \t Loss : 0.007586\n",
      "Train Epoch : 10, index : 100 \t Loss : 0.019053\n",
      "Train Epoch : 10, index : 110 \t Loss : 0.021530\n",
      "Test Average loss : 0.0001, Accuracy : 98.960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9 调用方法\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_model(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    test_model(model, DEVICE, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch for Deeplearning",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
